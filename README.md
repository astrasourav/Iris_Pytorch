# ğŸŒ¸ Iris Flower Classification using Neural Network (PyTorch)

## ğŸ“‘ Project Description

This is a simple **Neural Network (NN)** model built using **PyTorch** to classify the famous **Iris dataset** into its respective species:
- **Setosa**
- **Versicolor**
- **Virginica**

The model is trained and evaluated on the dataset, achieving high accuracy and good generalization.

---

## ğŸ’¾ Dataset

- **Dataset Source**: [Iris Dataset](https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv)
- **Features**:
  - Sepal Length
  - Sepal Width
  - Petal Length
  - Petal Width
- **Labels**:
  - Variety (species of Iris flower)

---

## âš™ï¸ Technologies & Libraries Used

- Python
- PyTorch
- Pandas
- NumPy
- Matplotlib
- scikit-learn (for train-test split)

---

## ğŸš€ Steps Performed

1. **Data Collection**: Collected Iris dataset from the web.
2. **Data Preprocessing**:
   - Encoded target labels (species names) to numerical format (0.0, 1.0, 2.0).
   - Split the dataset into **training and testing sets**.
   - Converted data into **PyTorch tensors** for model training.
3. **Model Building**:
   - Created a custom Neural Network using `torch.nn.Module`.
   - Network architecture:
     - Input layer: 4 neurons
     - Hidden layers: 2 hidden layers with 8 neurons each (ReLU activation)
     - Output layer: 3 neurons (for 3 classes)
4. **Training**:
   - Used **CrossEntropyLoss** as the loss function.
   - Optimized using **Adam optimizer**.
   - Trained for 100 epochs and plotted loss curve.
5. **Model Evaluation**:
   - Evaluated model on the test set.
   - Calculated **loss and accuracy**.
6. **Model Saving**:
   - Saved the trained model using `torch.save()` as `Iris_Model.pt`.
7. **Model Testing on New Data**:
   - Tested model on unseen/new data to predict flower variety.

---

## ğŸ“Š Observations

- The model achieved **100% accuracy** on the test set after training.
- Loss reduced significantly over epochs, demonstrating good learning.
- Model was able to correctly predict unseen data.
- **Effect of random seed and random_state**:
  - Observed that **higher values of random_state and manual_seed** sometimes caused **higher loss and reduced accuracy** due to the way the dataset was split and model initialized.
  - Lower values of seed and random_state often gave better splits and initializations, leading to **lower loss and higher accuracy**.
- Saved model (`.pt` file) can be reloaded and used for future predictions without retraining.

---
## ğŸ“¬ Contact
If you have any questions or suggestions, feel free to reach out! ğŸ˜Š  

ğŸ“§ **Email:** souravkumarr77@gmail.com  
ğŸ”— **LinkedIn:** [Sourav Kumar](https://www.linkedin.com/in/sourav-kumar-30141b174/)  
ğŸ”— **X:** [Sourav Kumar](https://x.com/souravkumarr73)  


